{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Asus\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Asus\\AppData\\Local\\Temp\\ipykernel_17484\\3236992082.py:25: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "# from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM  # Updated import paths\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import cycle\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>31338</td>\n",
       "      <td>145</td>\n",
       "      <td>26.67</td>\n",
       "      <td>398924026.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-09</td>\n",
       "      <td>33079</td>\n",
       "      <td>3220</td>\n",
       "      <td>26.12</td>\n",
       "      <td>379712121.0</td>\n",
       "      <td>-2.062242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-16</td>\n",
       "      <td>20892</td>\n",
       "      <td>3030</td>\n",
       "      <td>25.65</td>\n",
       "      <td>266617523.0</td>\n",
       "      <td>-1.799387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-23</td>\n",
       "      <td>34820</td>\n",
       "      <td>3539</td>\n",
       "      <td>26.18</td>\n",
       "      <td>409844550.0</td>\n",
       "      <td>2.066277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-30</td>\n",
       "      <td>26115</td>\n",
       "      <td>4112</td>\n",
       "      <td>26.32</td>\n",
       "      <td>347830186.0</td>\n",
       "      <td>0.534759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date    svi  edgar  price       volume  WeeklyReturns\n",
       "0   MSFT  2005-01-02  31338    145  26.67  398924026.0            NaN\n",
       "1   MSFT  2005-01-09  33079   3220  26.12  379712121.0      -2.062242\n",
       "2   MSFT  2005-01-16  20892   3030  25.65  266617523.0      -1.799387\n",
       "3   MSFT  2005-01-23  34820   3539  26.18  409844550.0       2.066277\n",
       "4   MSFT  2005-01-30  26115   4112  26.32  347830186.0       0.534759"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/returns_svi_edgar.csv')\n",
    "df = df[['symbol', 'date', 'svi.1', 'edgar', 'price', 'volume', 'WeeklyReturns']]\n",
    "df.rename(columns = {'svi.1':'svi'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['returns'] = df['WeeklyReturns'].apply(lambda x: np.round(x, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AAPL</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GOOG</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>PYPL</td>\n",
       "      <td>550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>VLO</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>BA.L</td>\n",
       "      <td>962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>HUM</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>GIII</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>392 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    symbol  total\n",
       "0     MSFT      0\n",
       "1     AAPL      0\n",
       "2     NVDA      0\n",
       "3     AMZN      0\n",
       "4     GOOG      0\n",
       "..     ...    ...\n",
       "387   PYPL    550\n",
       "388    VLO      0\n",
       "389   BA.L    962\n",
       "390    HUM      0\n",
       "391   GIII      0\n",
       "\n",
       "[392 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_na = pd.DataFrame(columns = ['symbol','total'])\n",
    "for s in df['symbol'].unique():\n",
    "     NAs = df.loc[df['symbol'] == s]['price'].isna().sum()\n",
    "     df_na.loc[len(df_na)] = {'symbol':s, 'total':NAs}\n",
    "\n",
    "df_na\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_symbols = df_na.loc[df_na['total'] > 0]['symbol'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287638\n",
      "299\n"
     ]
    }
   ],
   "source": [
    "# symbols with na data\n",
    "for s in na_symbols:\n",
    "     df = df.loc[df['symbol'] != s]\n",
    "\n",
    "print(len(df))\n",
    "print(df['symbol'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "278980\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "# some prices are zero\n",
    "minus_symbols = df.loc[df['price']<0]['symbol'].unique()\n",
    "for s in minus_symbols:\n",
    "     df = df.loc[df['symbol'] != s]\n",
    "\n",
    "print(len(df))\n",
    "print(df['symbol'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['WeeklyReturns'] = 0.0  # Initialize the column with zeros\n",
    "\n",
    "for company in df['symbol'].unique():\n",
    "    company_mask = df['symbol'] == company\n",
    "    df.loc[company_mask, 'WeeklyReturns'] = df.loc[company_mask, 'price'].pct_change() * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df['returns'] = df['WeeklyReturns'].apply(lambda x: np.round(x, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../data/new_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "column_data = df['returns']\n",
    "\n",
    "# Sample a subset of your data\n",
    "sample_size = min(10000, len(column_data))  # Adjust sample size as desired\n",
    "column_sample = column_data.sample(n=sample_size, random_state=1)\n",
    "\n",
    "# Plotting the histogram with the sampled data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(column_sample, kde=True)\n",
    "plt.title('Histogram of the Column (Sampled Data)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-02-27</td>\n",
       "      <td>44120</td>\n",
       "      <td>1521</td>\n",
       "      <td>42.81</td>\n",
       "      <td>1.343104e+08</td>\n",
       "      <td>-51.893471</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1157</th>\n",
       "      <td>1157</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2008-09-28</td>\n",
       "      <td>147802</td>\n",
       "      <td>4371</td>\n",
       "      <td>97.07</td>\n",
       "      <td>3.377796e+08</td>\n",
       "      <td>-24.305995</td>\n",
       "      <td>-24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1454</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2014-06-08</td>\n",
       "      <td>145264</td>\n",
       "      <td>89222</td>\n",
       "      <td>91.28</td>\n",
       "      <td>2.931859e+08</td>\n",
       "      <td>-85.860558</td>\n",
       "      <td>-86.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1779</th>\n",
       "      <td>1779</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2020-08-30</td>\n",
       "      <td>170600</td>\n",
       "      <td>7538</td>\n",
       "      <td>120.96</td>\n",
       "      <td>1.166973e+09</td>\n",
       "      <td>-75.770687</td>\n",
       "      <td>-76.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>1989</td>\n",
       "      <td>NVDA</td>\n",
       "      <td>2006-04-02</td>\n",
       "      <td>18212</td>\n",
       "      <td>0</td>\n",
       "      <td>30.53</td>\n",
       "      <td>4.539995e+07</td>\n",
       "      <td>-46.681802</td>\n",
       "      <td>-47.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278739</th>\n",
       "      <td>376602</td>\n",
       "      <td>HES</td>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>31500</td>\n",
       "      <td>511</td>\n",
       "      <td>60.21</td>\n",
       "      <td>3.099170e+07</td>\n",
       "      <td>20.564678</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278744</th>\n",
       "      <td>376607</td>\n",
       "      <td>HES</td>\n",
       "      <td>2008-11-30</td>\n",
       "      <td>28875</td>\n",
       "      <td>1802</td>\n",
       "      <td>38.49</td>\n",
       "      <td>3.006420e+07</td>\n",
       "      <td>-28.774981</td>\n",
       "      <td>-29.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278745</th>\n",
       "      <td>376608</td>\n",
       "      <td>HES</td>\n",
       "      <td>2008-12-07</td>\n",
       "      <td>33250</td>\n",
       "      <td>775</td>\n",
       "      <td>47.70</td>\n",
       "      <td>3.019850e+07</td>\n",
       "      <td>23.928293</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278811</th>\n",
       "      <td>376935</td>\n",
       "      <td>STM</td>\n",
       "      <td>2020-03-15</td>\n",
       "      <td>122721</td>\n",
       "      <td>0</td>\n",
       "      <td>16.42</td>\n",
       "      <td>2.073260e+07</td>\n",
       "      <td>-23.019222</td>\n",
       "      <td>-23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278812</th>\n",
       "      <td>376936</td>\n",
       "      <td>STM</td>\n",
       "      <td>2020-03-22</td>\n",
       "      <td>99038</td>\n",
       "      <td>0</td>\n",
       "      <td>20.22</td>\n",
       "      <td>1.484281e+07</td>\n",
       "      <td>23.142509</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1742 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         index symbol       date     svi  edgar   price        volume  \\\n",
       "970        970   AAPL 2005-02-27   44120   1521   42.81  1.343104e+08   \n",
       "1157      1157   AAPL 2008-09-28  147802   4371   97.07  3.377796e+08   \n",
       "1454      1454   AAPL 2014-06-08  145264  89222   91.28  2.931859e+08   \n",
       "1779      1779   AAPL 2020-08-30  170600   7538  120.96  1.166973e+09   \n",
       "1989      1989   NVDA 2006-04-02   18212      0   30.53  4.539995e+07   \n",
       "...        ...    ...        ...     ...    ...     ...           ...   \n",
       "278739  376602    HES 2008-10-26   31500    511   60.21  3.099170e+07   \n",
       "278744  376607    HES 2008-11-30   28875   1802   38.49  3.006420e+07   \n",
       "278745  376608    HES 2008-12-07   33250    775   47.70  3.019850e+07   \n",
       "278811  376935    STM 2020-03-15  122721      0   16.42  2.073260e+07   \n",
       "278812  376936    STM 2020-03-22   99038      0   20.22  1.484281e+07   \n",
       "\n",
       "        WeeklyReturns  returns  \n",
       "970        -51.893471    -52.0  \n",
       "1157       -24.305995    -24.0  \n",
       "1454       -85.860558    -86.0  \n",
       "1779       -75.770687    -76.0  \n",
       "1989       -46.681802    -47.0  \n",
       "...               ...      ...  \n",
       "278739      20.564678     21.0  \n",
       "278744     -28.774981    -29.0  \n",
       "278745      23.928293     24.0  \n",
       "278811     -23.019222    -23.0  \n",
       "278812      23.142509     23.0  \n",
       "\n",
       "[1742 rows x 9 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df['returns']>20) | (df['returns']<-20)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.loc[(df['returns']>20) | (df['returns']<-20)]\n",
    "test = test.loc[test['date'].dt.year >= 2005]\n",
    "len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1919</th>\n",
       "      <td>1919</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-05-07</td>\n",
       "      <td>25590</td>\n",
       "      <td>56247</td>\n",
       "      <td>172.57001</td>\n",
       "      <td>249685623.0</td>\n",
       "      <td>-0.576136</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1920</th>\n",
       "      <td>1920</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-05-14</td>\n",
       "      <td>25590</td>\n",
       "      <td>57743</td>\n",
       "      <td>175.16000</td>\n",
       "      <td>258452789.0</td>\n",
       "      <td>1.500834</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1921</th>\n",
       "      <td>1921</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-05-21</td>\n",
       "      <td>25590</td>\n",
       "      <td>45344</td>\n",
       "      <td>175.42999</td>\n",
       "      <td>250258640.0</td>\n",
       "      <td>0.154139</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1922</th>\n",
       "      <td>1922</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-05-28</td>\n",
       "      <td>27296</td>\n",
       "      <td>45063</td>\n",
       "      <td>180.95000</td>\n",
       "      <td>286095295.0</td>\n",
       "      <td>3.146560</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1923</th>\n",
       "      <td>1923</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2023-06-04</td>\n",
       "      <td>44356</td>\n",
       "      <td>158695</td>\n",
       "      <td>180.96001</td>\n",
       "      <td>348117069.0</td>\n",
       "      <td>0.005532</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index symbol        date    svi   edgar      price       volume  \\\n",
       "1919   1919   AAPL  2023-05-07  25590   56247  172.57001  249685623.0   \n",
       "1920   1920   AAPL  2023-05-14  25590   57743  175.16000  258452789.0   \n",
       "1921   1921   AAPL  2023-05-21  25590   45344  175.42999  250258640.0   \n",
       "1922   1922   AAPL  2023-05-28  27296   45063  180.95000  286095295.0   \n",
       "1923   1923   AAPL  2023-06-04  44356  158695  180.96001  348117069.0   \n",
       "\n",
       "      WeeklyReturns  returns  \n",
       "1919      -0.576136     -1.0  \n",
       "1920       1.500834      2.0  \n",
       "1921       0.154139      0.0  \n",
       "1922       3.146560      3.0  \n",
       "1923       0.005532      0.0  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[df['symbol'] == 'AAPL'].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>969</th>\n",
       "      <td>969</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-02-20</td>\n",
       "      <td>35296</td>\n",
       "      <td>1921</td>\n",
       "      <td>88.99</td>\n",
       "      <td>89615748.0</td>\n",
       "      <td>2.511231</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>970</th>\n",
       "      <td>970</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-02-27</td>\n",
       "      <td>44120</td>\n",
       "      <td>1521</td>\n",
       "      <td>42.81</td>\n",
       "      <td>134310408.0</td>\n",
       "      <td>-51.893471</td>\n",
       "      <td>-52.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>971</th>\n",
       "      <td>971</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-03-06</td>\n",
       "      <td>30884</td>\n",
       "      <td>1909</td>\n",
       "      <td>40.27</td>\n",
       "      <td>150452794.0</td>\n",
       "      <td>-5.933193</td>\n",
       "      <td>-6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>972</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>2005-03-13</td>\n",
       "      <td>26472</td>\n",
       "      <td>2410</td>\n",
       "      <td>42.96</td>\n",
       "      <td>129461707.0</td>\n",
       "      <td>6.679911</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index symbol        date    svi  edgar  price       volume  \\\n",
       "969    969   AAPL  2005-02-20  35296   1921  88.99   89615748.0   \n",
       "970    970   AAPL  2005-02-27  44120   1521  42.81  134310408.0   \n",
       "971    971   AAPL  2005-03-06  30884   1909  40.27  150452794.0   \n",
       "972    972   AAPL  2005-03-13  26472   2410  42.96  129461707.0   \n",
       "\n",
       "     WeeklyReturns  returns  \n",
       "969       2.511231      3.0  \n",
       "970     -51.893471    -52.0  \n",
       "971      -5.933193     -6.0  \n",
       "972       6.679911      7.0  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[969:973]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Quartile (Q1): -2.0\n",
      "Median (Q2): -0.0\n",
      "3rd Quartile (Q3): 2.0\n"
     ]
    }
   ],
   "source": [
    "# Getting specific quartiles\n",
    "Q1 = column_data.quantile(0.25)\n",
    "Q2 = column_data.quantile(0.5)  # Median\n",
    "Q3 = column_data.quantile(0.75)\n",
    "\n",
    "print(f\"1st Quartile (Q1): {Q1}\")\n",
    "print(f\"Median (Q2): {Q2}\")\n",
    "print(f\"3rd Quartile (Q3): {Q3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling returns\n",
    "def labeling(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          if r <= 2:\n",
    "               l = 1\n",
    "          else : \n",
    "               l = 2\n",
    "\n",
    "     elif r < 0:\n",
    "          if r >= -2:\n",
    "               l = 3\n",
    "          else : \n",
    "               l = 4\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagger(df, col,num):\n",
    "    df[f'shifted-({num})']  = df[col].shift(num)\n",
    "    return df\n",
    "\n",
    "def ticker_initialization(symbol, lag):\n",
    "     df_symbol = df.loc[df['symbol'] == symbol]\n",
    "     df_symbol = lagger(df_symbol, 'labeled_returns', -lag)\n",
    "     \n",
    "     start = 0\n",
    "     end = len(df_symbol) - lag\n",
    "     df_symbol = df_symbol[start:end]\n",
    "     df_symbol.reset_index(inplace = True)\n",
    "\n",
    "     return df_symbol\n",
    "\n",
    "def standardize(column):\n",
    "    mean_value = column.mean()\n",
    "    std_dev = column.std()\n",
    "    scaled_column = (column - mean_value) / std_dev\n",
    "    return scaled_column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244840, 2, 2) (244840,)\n"
     ]
    }
   ],
   "source": [
    "# creating batches and test, train size\n",
    "Xs, ys = [], []\n",
    "for t in df['symbol'].unique():\n",
    "     lag = 1\n",
    "     x = ticker_initialization(t , lag)\n",
    "     x['input-1'] = standardize(x['svi'])\n",
    "     x['input-2'] = standardize(x['edgar'])\n",
    "     x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "     X = x[['input-1', 'input-2']]\n",
    "     y = x['output']\n",
    "     time_steps = 2\n",
    "     \n",
    "     for i in range(len(X) - time_steps):\n",
    "          x_array = X.iloc[i:(i + time_steps)].values\n",
    "          y_array = y.iloc[i + time_steps]\n",
    "          if not np.isnan(x_array).any():\n",
    "               if not np.isnan(y_array).any() :\n",
    "                    Xs.append(x_array)\n",
    "                    ys.append(y_array)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 9s 22ms/step - loss: 1.5930 - accuracy: 0.2402 - val_loss: 1.5715 - val_accuracy: 0.2746\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 1.5916 - accuracy: 0.2441 - val_loss: 1.5719 - val_accuracy: 0.2731\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 1.5908 - accuracy: 0.2456 - val_loss: 1.5711 - val_accuracy: 0.2716\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming your labels are integer encoded, convert them to one-hot\n",
    "y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# number_of_features is the number of features in your input data\n",
    "number_of_features = X.shape[1]\n",
    "\n",
    "# Adjust the model for multiclass classification\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(time_steps, number_of_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model using the one-hot encoded labels\n",
    "history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                    validation_data=(X_test, y_test_onehot),\n",
    "                    verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 123, 'time_steps': 123}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "results.append({'acc':123, 'time_steps': 123})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 32s 116ms/step - loss: 1.5920 - accuracy: 0.2450 - val_loss: 1.5643 - val_accuracy: 0.2761\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 28s 115ms/step - loss: 1.5908 - accuracy: 0.2492 - val_loss: 1.5683 - val_accuracy: 0.2753\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 27s 112ms/step - loss: 1.5900 - accuracy: 0.2501 - val_loss: 1.5679 - val_accuracy: 0.2741\n",
      "0.2740858495235443\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 34s 127ms/step - loss: 1.5925 - accuracy: 0.2427 - val_loss: 1.5668 - val_accuracy: 0.2730\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 28s 116ms/step - loss: 1.5912 - accuracy: 0.2472 - val_loss: 1.5674 - val_accuracy: 0.2752\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 26s 109ms/step - loss: 1.5906 - accuracy: 0.2486 - val_loss: 1.5688 - val_accuracy: 0.2736\n",
      "0.2735670804977417\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 34s 128ms/step - loss: 1.5926 - accuracy: 0.2453 - val_loss: 1.5640 - val_accuracy: 0.2761\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 29s 122ms/step - loss: 1.5908 - accuracy: 0.2490 - val_loss: 1.5664 - val_accuracy: 0.2740\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 29s 121ms/step - loss: 1.5896 - accuracy: 0.2502 - val_loss: 1.5659 - val_accuracy: 0.2737\n",
      "0.2737278938293457\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 36s 134ms/step - loss: 1.5923 - accuracy: 0.2434 - val_loss: 1.5656 - val_accuracy: 0.2724\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 34s 139ms/step - loss: 1.5908 - accuracy: 0.2492 - val_loss: 1.5665 - val_accuracy: 0.2736\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 32s 132ms/step - loss: 1.5899 - accuracy: 0.2504 - val_loss: 1.5651 - val_accuracy: 0.2722\n",
      "0.27216073870658875\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 37s 140ms/step - loss: 1.5923 - accuracy: 0.2438 - val_loss: 1.5641 - val_accuracy: 0.2774\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 33s 136ms/step - loss: 1.5909 - accuracy: 0.2479 - val_loss: 1.5641 - val_accuracy: 0.2732\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5897 - accuracy: 0.2505 - val_loss: 1.5645 - val_accuracy: 0.2743\n",
      "0.2743166983127594\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 38s 146ms/step - loss: 1.5925 - accuracy: 0.2429 - val_loss: 1.5654 - val_accuracy: 0.2741\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5916 - accuracy: 0.2468 - val_loss: 1.5683 - val_accuracy: 0.2741\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5903 - accuracy: 0.2485 - val_loss: 1.5671 - val_accuracy: 0.2757\n",
      "0.27566108107566833\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 41s 155ms/step - loss: 1.5927 - accuracy: 0.2418 - val_loss: 1.5673 - val_accuracy: 0.2746\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 37s 153ms/step - loss: 1.5915 - accuracy: 0.2467 - val_loss: 1.5696 - val_accuracy: 0.2752\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 35s 146ms/step - loss: 1.5904 - accuracy: 0.2476 - val_loss: 1.5677 - val_accuracy: 0.2756\n",
      "0.2755579948425293\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 41s 156ms/step - loss: 1.5922 - accuracy: 0.2419 - val_loss: 1.5657 - val_accuracy: 0.2751\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 37s 155ms/step - loss: 1.5916 - accuracy: 0.2452 - val_loss: 1.5681 - val_accuracy: 0.2732\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 37s 154ms/step - loss: 1.5900 - accuracy: 0.2495 - val_loss: 1.5658 - val_accuracy: 0.2754\n",
      "0.27543801069259644\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 42s 162ms/step - loss: 1.5928 - accuracy: 0.2433 - val_loss: 1.5658 - val_accuracy: 0.2757\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 39s 160ms/step - loss: 1.5915 - accuracy: 0.2460 - val_loss: 1.5657 - val_accuracy: 0.2758\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 42s 176ms/step - loss: 1.5904 - accuracy: 0.2491 - val_loss: 1.5659 - val_accuracy: 0.2739\n",
      "0.27386459708213806\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,25,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 0.2714589238166809, 'time_steps': 2},\n",
       " {'acc': 0.27156174182891846, 'time_steps': 3},\n",
       " {'acc': 0.2733061611652374, 'time_steps': 4},\n",
       " {'acc': 0.27207183837890625, 'time_steps': 5},\n",
       " {'acc': 0.2734266221523285, 'time_steps': 6},\n",
       " {'acc': 0.27332282066345215, 'time_steps': 7},\n",
       " {'acc': 0.27441859245300293, 'time_steps': 8},\n",
       " {'acc': 0.27429914474487305, 'time_steps': 9},\n",
       " {'acc': 0.27386656403541565, 'time_steps': 10},\n",
       " {'acc': 0.2753453552722931, 'time_steps': 11},\n",
       " {'acc': 0.2750449776649475, 'time_steps': 12},\n",
       " {'acc': 0.27419888973236084, 'time_steps': 13},\n",
       " {'acc': 0.2769060432910919, 'time_steps': 14},\n",
       " {'acc': 0.2757952809333801, 'time_steps': 15},\n",
       " {'acc': 0.2740858495235443, 'time_steps': 16},\n",
       " {'acc': 0.2735670804977417, 'time_steps': 17},\n",
       " {'acc': 0.2737278938293457, 'time_steps': 18},\n",
       " {'acc': 0.27216073870658875, 'time_steps': 19},\n",
       " {'acc': 0.2743166983127594, 'time_steps': 20},\n",
       " {'acc': 0.27566108107566833, 'time_steps': 21},\n",
       " {'acc': 0.2755579948425293, 'time_steps': 22},\n",
       " {'acc': 0.27543801069259644, 'time_steps': 23},\n",
       " {'acc': 0.27386459708213806, 'time_steps': 24}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 10s 25ms/step - loss: 1.0762 - accuracy: 0.4504 - val_loss: 0.9713 - val_accuracy: 0.4283\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 5s 22ms/step - loss: 0.9954 - accuracy: 0.4627 - val_loss: 0.9704 - val_accuracy: 0.4283\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 5s 21ms/step - loss: 0.9947 - accuracy: 0.4636 - val_loss: 0.9703 - val_accuracy: 0.4283\n",
      "0.42834505438804626\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 11s 30ms/step - loss: 1.0680 - accuracy: 0.4577 - val_loss: 0.9699 - val_accuracy: 0.4284\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 7s 29ms/step - loss: 0.9959 - accuracy: 0.4620 - val_loss: 0.9695 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.9950 - accuracy: 0.4632 - val_loss: 0.9691 - val_accuracy: 0.4284\n",
      "0.428372859954834\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 14s 40ms/step - loss: 1.0609 - accuracy: 0.4527 - val_loss: 0.9698 - val_accuracy: 0.4291\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.9957 - accuracy: 0.4605 - val_loss: 0.9702 - val_accuracy: 0.4288\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.9948 - accuracy: 0.4627 - val_loss: 0.9702 - val_accuracy: 0.4287\n",
      "0.42866963148117065\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 15s 46ms/step - loss: 1.0597 - accuracy: 0.4567 - val_loss: 0.9705 - val_accuracy: 0.4287\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 0.9959 - accuracy: 0.4604 - val_loss: 0.9693 - val_accuracy: 0.4286\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 0.9948 - accuracy: 0.4630 - val_loss: 0.9687 - val_accuracy: 0.4287\n",
      "0.4286557137966156\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 17s 53ms/step - loss: 1.0505 - accuracy: 0.4533 - val_loss: 0.9699 - val_accuracy: 0.4360\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 12s 47ms/step - loss: 0.9963 - accuracy: 0.4615 - val_loss: 0.9696 - val_accuracy: 0.4285\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 12s 49ms/step - loss: 0.9952 - accuracy: 0.4624 - val_loss: 0.9694 - val_accuracy: 0.4285\n",
      "0.4285432994365692\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 18s 58ms/step - loss: 1.0481 - accuracy: 0.4533 - val_loss: 0.9721 - val_accuracy: 0.4287\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 14s 58ms/step - loss: 0.9965 - accuracy: 0.4613 - val_loss: 0.9706 - val_accuracy: 0.4287\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 14s 57ms/step - loss: 0.9952 - accuracy: 0.4624 - val_loss: 0.9694 - val_accuracy: 0.4287\n",
      "0.4286605715751648\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 21s 69ms/step - loss: 1.0436 - accuracy: 0.4488 - val_loss: 0.9683 - val_accuracy: 0.4417\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.9971 - accuracy: 0.4567 - val_loss: 0.9686 - val_accuracy: 0.4328\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 15s 63ms/step - loss: 0.9954 - accuracy: 0.4599 - val_loss: 0.9686 - val_accuracy: 0.4283\n",
      "0.4283014237880707\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 21s 72ms/step - loss: 1.0418 - accuracy: 0.4517 - val_loss: 0.9693 - val_accuracy: 0.4284\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 0.9717 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.9944 - accuracy: 0.4619 - val_loss: 0.9709 - val_accuracy: 0.4284\n",
      "0.4284351170063019\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 23s 79ms/step - loss: 1.0433 - accuracy: 0.4471 - val_loss: 0.9695 - val_accuracy: 0.4308\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 18s 76ms/step - loss: 0.9962 - accuracy: 0.4592 - val_loss: 0.9696 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 18s 75ms/step - loss: 0.9952 - accuracy: 0.4612 - val_loss: 0.9692 - val_accuracy: 0.4284\n",
      "0.42840439081192017\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 25s 86ms/step - loss: 1.0345 - accuracy: 0.4488 - val_loss: 0.9709 - val_accuracy: 0.4390\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 20s 81ms/step - loss: 0.9963 - accuracy: 0.4582 - val_loss: 0.9690 - val_accuracy: 0.4283\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 0.9952 - accuracy: 0.4605 - val_loss: 0.9683 - val_accuracy: 0.4279\n",
      "0.42787906527519226\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 27s 94ms/step - loss: 1.0352 - accuracy: 0.4521 - val_loss: 0.9711 - val_accuracy: 0.4289\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 0.9964 - accuracy: 0.4580 - val_loss: 0.9703 - val_accuracy: 0.4295\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 22s 89ms/step - loss: 0.9948 - accuracy: 0.4608 - val_loss: 0.9684 - val_accuracy: 0.4289\n",
      "0.4288873076438904\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 28s 101ms/step - loss: 1.0404 - accuracy: 0.4532 - val_loss: 0.9717 - val_accuracy: 0.4281\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 24s 98ms/step - loss: 0.9960 - accuracy: 0.4619 - val_loss: 0.9701 - val_accuracy: 0.4281\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 23s 96ms/step - loss: 0.9947 - accuracy: 0.4629 - val_loss: 0.9696 - val_accuracy: 0.4281\n",
      "0.4280640780925751\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 29s 106ms/step - loss: 1.0451 - accuracy: 0.4460 - val_loss: 0.9688 - val_accuracy: 0.4384\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 24s 101ms/step - loss: 0.9962 - accuracy: 0.4597 - val_loss: 0.9697 - val_accuracy: 0.4338\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 25s 103ms/step - loss: 0.9946 - accuracy: 0.4623 - val_loss: 0.9701 - val_accuracy: 0.4276\n",
      "0.4276195168495178\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 31s 114ms/step - loss: 1.0340 - accuracy: 0.4528 - val_loss: 0.9697 - val_accuracy: 0.4324\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 26s 108ms/step - loss: 0.9955 - accuracy: 0.4608 - val_loss: 0.9713 - val_accuracy: 0.4287\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 27s 110ms/step - loss: 0.9947 - accuracy: 0.4615 - val_loss: 0.9698 - val_accuracy: 0.4301\n",
      "0.43013671040534973\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_2(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          l = 1\n",
    "     elif r < 0:\n",
    "          l = 2\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_2)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(2,16,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.9982 - accuracy: 0.4640 - val_loss: 0.9669 - val_accuracy: 0.4457\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.9934 - accuracy: 0.4645 - val_loss: 0.9658 - val_accuracy: 0.4542\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.9927 - accuracy: 0.4650 - val_loss: 0.9654 - val_accuracy: 0.4596\n",
      "0.45956557989120483\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_2(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          l = 1\n",
    "     elif r < 0:\n",
    "          l = 2\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_2)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,17,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=3)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(3, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results-checkpoint', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'acc': 0.2714589238166809, 'time_steps': 2},\n",
       "       {'acc': 0.27156174182891846, 'time_steps': 3},\n",
       "       {'acc': 0.2733061611652374, 'time_steps': 4},\n",
       "       {'acc': 0.27207183837890625, 'time_steps': 5},\n",
       "       {'acc': 0.2734266221523285, 'time_steps': 6},\n",
       "       {'acc': 0.27332282066345215, 'time_steps': 7},\n",
       "       {'acc': 0.27441859245300293, 'time_steps': 8},\n",
       "       {'acc': 0.27429914474487305, 'time_steps': 9},\n",
       "       {'acc': 0.27386656403541565, 'time_steps': 10},\n",
       "       {'acc': 0.2753453552722931, 'time_steps': 11},\n",
       "       {'acc': 0.2750449776649475, 'time_steps': 12},\n",
       "       {'acc': 0.27419888973236084, 'time_steps': 13},\n",
       "       {'acc': 0.2769060432910919, 'time_steps': 14},\n",
       "       {'acc': 0.2757952809333801, 'time_steps': 15},\n",
       "       {'acc': 0.2740858495235443, 'time_steps': 16},\n",
       "       {'acc': 0.2735670804977417, 'time_steps': 17},\n",
       "       {'acc': 0.2737278938293457, 'time_steps': 18},\n",
       "       {'acc': 0.27216073870658875, 'time_steps': 19},\n",
       "       {'acc': 0.2743166983127594, 'time_steps': 20},\n",
       "       {'acc': 0.27566108107566833, 'time_steps': 21},\n",
       "       {'acc': 0.2755579948425293, 'time_steps': 22},\n",
       "       {'acc': 0.27543801069259644, 'time_steps': 23},\n",
       "       {'acc': 0.27386459708213806, 'time_steps': 24},\n",
       "       {'acc': 0.42834505438804626, 'time_steps': 2, 'new': 123},\n",
       "       {'acc': 0.428372859954834, 'time_steps': 3, 'new': 123},\n",
       "       {'acc': 0.42866963148117065, 'time_steps': 4, 'new': 123},\n",
       "       {'acc': 0.4286557137966156, 'time_steps': 5, 'new': 123},\n",
       "       {'acc': 0.4285432994365692, 'time_steps': 6, 'new': 123},\n",
       "       {'acc': 0.4286605715751648, 'time_steps': 7, 'new': 123},\n",
       "       {'acc': 0.4283014237880707, 'time_steps': 8, 'new': 123},\n",
       "       {'acc': 0.4284351170063019, 'time_steps': 9, 'new': 123},\n",
       "       {'acc': 0.42840439081192017, 'time_steps': 10, 'new': 123},\n",
       "       {'acc': 0.42787906527519226, 'time_steps': 11, 'new': 123},\n",
       "       {'acc': 0.4288873076438904, 'time_steps': 12, 'new': 123},\n",
       "       {'acc': 0.4280640780925751, 'time_steps': 13, 'new': 123},\n",
       "       {'acc': 0.4276195168495178, 'time_steps': 14, 'new': 123},\n",
       "       {'acc': 0.43013671040534973, 'time_steps': 15, 'new': 123},\n",
       "       {'acc': 0.4284175932407379, 'time_steps': 16, 'new': 123},\n",
       "       {'acc': 0.42777299880981445, 'time_steps': 17, 'new': 123},\n",
       "       {'acc': 0.4275919198989868, 'time_steps': 18, 'new': 123},\n",
       "       {'acc': 0.427875816822052, 'time_steps': 19, 'new': 123},\n",
       "       {'acc': 0.42791077494621277, 'time_steps': 20, 'new': 123},\n",
       "       {'acc': 0.44436487555503845, 'time_steps': 21, 'new': 123},\n",
       "       {'acc': 0.4283309280872345, 'time_steps': 22, 'new': 123},\n",
       "       {'acc': 0.4288002550601959, 'time_steps': 23, 'new': 123},\n",
       "       {'acc': 0.42796772718429565, 'time_steps': 24, 'new': 123},\n",
       "       {'acc': 0.4281199872493744, 'time_steps': 25, 'new': 123}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.load('results-checkpoint.npy', allow_pickle=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 24s 83ms/step - loss: 0.6832 - accuracy: 0.5618 - val_loss: 0.6930 - val_accuracy: 0.4975\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.6827 - accuracy: 0.5602 - val_loss: 0.6938 - val_accuracy: 0.4747\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.6821 - accuracy: 0.5627 - val_loss: 0.6940 - val_accuracy: 0.4718\n",
      "0.4717928469181061\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 28s 99ms/step - loss: 0.6836 - accuracy: 0.5608 - val_loss: 0.6940 - val_accuracy: 0.4710\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 23s 96ms/step - loss: 0.6832 - accuracy: 0.5597 - val_loss: 0.6943 - val_accuracy: 0.4768\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 23s 95ms/step - loss: 0.6826 - accuracy: 0.5627 - val_loss: 0.6945 - val_accuracy: 0.4724\n",
      "0.47235307097435\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 28s 99ms/step - loss: 0.6834 - accuracy: 0.5618 - val_loss: 0.6937 - val_accuracy: 0.4831\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 22s 90ms/step - loss: 0.6828 - accuracy: 0.5606 - val_loss: 0.6943 - val_accuracy: 0.4710\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 22s 90ms/step - loss: 0.6820 - accuracy: 0.5630 - val_loss: 0.6947 - val_accuracy: 0.4712\n",
      "0.47122105956077576\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_3(r):\n",
    "    if -2 <= r <= 2:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -2 or r > 2:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_3)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 25s 85ms/step - loss: 0.5213 - accuracy: 0.7876 - val_loss: 0.6120 - val_accuracy: 0.6935\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 0.5145 - accuracy: 0.7883 - val_loss: 0.6123 - val_accuracy: 0.6935\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 0.5129 - accuracy: 0.7883 - val_loss: 0.6127 - val_accuracy: 0.6935\n",
      "0.693540096282959\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 26s 92ms/step - loss: 0.5234 - accuracy: 0.7861 - val_loss: 0.6118 - val_accuracy: 0.6935\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 21s 86ms/step - loss: 0.5149 - accuracy: 0.7883 - val_loss: 0.6119 - val_accuracy: 0.6935\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 21s 86ms/step - loss: 0.5134 - accuracy: 0.7883 - val_loss: 0.6120 - val_accuracy: 0.6935\n",
      "0.6935120224952698\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 26s 93ms/step - loss: 0.5222 - accuracy: 0.7870 - val_loss: 0.6121 - val_accuracy: 0.6936\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 21s 87ms/step - loss: 0.5145 - accuracy: 0.7883 - val_loss: 0.6124 - val_accuracy: 0.6936\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 21s 86ms/step - loss: 0.5128 - accuracy: 0.7883 - val_loss: 0.6129 - val_accuracy: 0.6936\n",
      "0.6935834884643555\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r):\n",
    "    if -4 <= r <= 4:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -4 or r > 4:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_4)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'very extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 25s 85ms/step - loss: 0.3568 - accuracy: 0.8894 - val_loss: 0.4691 - val_accuracy: 0.8178\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 80ms/step - loss: 0.3402 - accuracy: 0.8930 - val_loss: 0.4687 - val_accuracy: 0.8178\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 80ms/step - loss: 0.3385 - accuracy: 0.8930 - val_loss: 0.4688 - val_accuracy: 0.8178\n",
      "0.8177510499954224\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 27s 92ms/step - loss: 0.3567 - accuracy: 0.8910 - val_loss: 0.4693 - val_accuracy: 0.8177\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 22s 89ms/step - loss: 0.3409 - accuracy: 0.8930 - val_loss: 0.4691 - val_accuracy: 0.8177\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 22s 89ms/step - loss: 0.3386 - accuracy: 0.8930 - val_loss: 0.4690 - val_accuracy: 0.8177\n",
      "0.8176827430725098\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 28s 100ms/step - loss: 0.3607 - accuracy: 0.8874 - val_loss: 0.4687 - val_accuracy: 0.8177\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 22s 93ms/step - loss: 0.3396 - accuracy: 0.8930 - val_loss: 0.4690 - val_accuracy: 0.8177\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 23s 93ms/step - loss: 0.3387 - accuracy: 0.8930 - val_loss: 0.4691 - val_accuracy: 0.8177\n",
      "0.8176973462104797\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r):\n",
    "    if -6 <= r <= 6:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -6 or r > 6:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_4)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'very very extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311.4485902178977"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['returns'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 24s 83ms/step - loss: 0.1771 - accuracy: 0.9607 - val_loss: 0.2576 - val_accuracy: 0.9278\n",
      "0.9277963042259216\n",
      "242/242 [==============================] - 25s 86ms/step - loss: 0.0933 - accuracy: 0.9847 - val_loss: 0.1322 - val_accuracy: 0.9701\n",
      "0.9701443314552307\n",
      "242/242 [==============================] - 24s 83ms/step - loss: 0.0774 - accuracy: 0.9840 - val_loss: 0.0784 - val_accuracy: 0.9849\n",
      "0.9848899245262146\n",
      "242/242 [==============================] - 24s 80ms/step - loss: 0.0481 - accuracy: 0.9961 - val_loss: 0.0532 - val_accuracy: 0.9904\n",
      "0.9904070496559143\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.0690 - accuracy: 0.9924 - val_loss: 0.0771 - val_accuracy: 0.9849\n",
      "0.9848899245262146\n",
      "242/242 [==============================] - 23s 78ms/step - loss: 0.0561 - accuracy: 0.9932 - val_loss: 0.0532 - val_accuracy: 0.9904\n",
      "0.9904070496559143\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.0433 - accuracy: 0.9957 - val_loss: 0.0410 - val_accuracy: 0.9932\n",
      "0.993240237236023\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0410 - accuracy: 0.9937 - val_loss: 0.0325 - val_accuracy: 0.9948\n",
      "0.9948307275772095\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0350 - accuracy: 0.9982 - val_loss: 0.0291 - val_accuracy: 0.9956\n",
      "0.9955928921699524\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0460 - accuracy: 0.9910 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
      "0.9961727857589722\n",
      "242/242 [==============================] - 24s 79ms/step - loss: 0.0348 - accuracy: 0.9970 - val_loss: 0.0240 - val_accuracy: 0.9966\n",
      "0.9965869784355164\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0371 - accuracy: 0.9953 - val_loss: 0.0227 - val_accuracy: 0.9968\n",
      "0.9968023300170898\n",
      "242/242 [==============================] - 23s 77ms/step - loss: 0.0320 - accuracy: 0.9969 - val_loss: 0.0219 - val_accuracy: 0.9970\n",
      "0.9969680309295654\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r,e):\n",
    "    if -e <= r <= e: \n",
    "        l = 0\n",
    "    elif r < -e or r > e:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "\n",
    "for e in [10,15,20,25,20,25,30,35,40,45,50,55,60]:\n",
    "\n",
    "     df['labeled_returns'] = df['returns'].apply(lambda x: labeling_4(x,e))\n",
    "     # results = []\n",
    "     for tl in np.arange(16,17,1):\n",
    "          Xs, ys = [], []\n",
    "          for t in df['symbol'].unique():\n",
    "               lag = 1\n",
    "               x = ticker_initialization(t , lag)\n",
    "               x['input-1'] = standardize(x['svi'])\n",
    "               x['input-2'] = standardize(x['edgar'])\n",
    "               x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "               X = x[['input-1', 'input-2']]\n",
    "               y = x['output']\n",
    "               time_steps = tl\n",
    "               \n",
    "               for i in range(len(X) - time_steps):\n",
    "                    x_array = X.iloc[i:(i + time_steps)].values\n",
    "                    y_array = y.iloc[i + time_steps]\n",
    "                    if not np.isnan(x_array).any():\n",
    "                         if not np.isnan(y_array).any() :\n",
    "                              Xs.append(x_array)\n",
    "                              ys.append(y_array)\n",
    "\n",
    "          X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "          y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "          y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "          # number_of_features is the number of features in your input data\n",
    "          number_of_features = X.shape[1]\n",
    "\n",
    "          # Adjust the model for multiclass classification\n",
    "          model = Sequential([\n",
    "          LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "          Dropout(0.2),\n",
    "          LSTM(100, return_sequences=False),\n",
    "          Dropout(0.2),\n",
    "          Dense(50, activation='relu'),\n",
    "          Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "          ])\n",
    "          model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "          early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "          # Fit the model using the one-hot encoded labels\n",
    "          history = model.fit(X_train, y_train_onehot, epochs=1, batch_size=1000,\n",
    "                              validation_data=(X_test, y_test_onehot),\n",
    "                              verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "          acc = history.history['val_accuracy'][-1]\n",
    "          print(acc)\n",
    "          results.append({'acc':acc, 'time_steps': tl, 'new':f'very very extreme {e}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
