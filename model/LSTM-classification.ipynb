{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\hgnik\\anaconda3\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hgnik\\AppData\\Local\\Temp\\ipykernel_17888\\3236992082.py:25: MatplotlibDeprecationWarning: The seaborn styles shipped by Matplotlib are deprecated since 3.6, as they no longer correspond to the styles shipped by seaborn. However, they will remain available as 'seaborn-v0_8-<style>'. Alternatively, directly use the seaborn API instead.\n",
      "  plt.style.use('seaborn-darkgrid')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, explained_variance_score, r2_score\n",
    "# from sklearn.metrics import mean_poisson_deviance, mean_gamma_deviance, accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from itertools import product\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM  # Updated import paths\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "\n",
    "from itertools import cycle\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "\n",
    "plt.style.use('seaborn-darkgrid')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-02</td>\n",
       "      <td>31338</td>\n",
       "      <td>145</td>\n",
       "      <td>26.67</td>\n",
       "      <td>398924026.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-09</td>\n",
       "      <td>33079</td>\n",
       "      <td>3220</td>\n",
       "      <td>26.12</td>\n",
       "      <td>379712121.0</td>\n",
       "      <td>-2.062242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-16</td>\n",
       "      <td>20892</td>\n",
       "      <td>3030</td>\n",
       "      <td>25.65</td>\n",
       "      <td>266617523.0</td>\n",
       "      <td>-1.799387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-23</td>\n",
       "      <td>34820</td>\n",
       "      <td>3539</td>\n",
       "      <td>26.18</td>\n",
       "      <td>409844550.0</td>\n",
       "      <td>2.066277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>MSFT</td>\n",
       "      <td>2005-01-30</td>\n",
       "      <td>26115</td>\n",
       "      <td>4112</td>\n",
       "      <td>26.32</td>\n",
       "      <td>347830186.0</td>\n",
       "      <td>0.534759</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  symbol        date    svi  edgar  price       volume  WeeklyReturns\n",
       "0   MSFT  2005-01-02  31338    145  26.67  398924026.0            NaN\n",
       "1   MSFT  2005-01-09  33079   3220  26.12  379712121.0      -2.062242\n",
       "2   MSFT  2005-01-16  20892   3030  25.65  266617523.0      -1.799387\n",
       "3   MSFT  2005-01-23  34820   3539  26.18  409844550.0       2.066277\n",
       "4   MSFT  2005-01-30  26115   4112  26.32  347830186.0       0.534759"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/returns_svi_edgar.csv')\n",
    "df = df[['symbol', 'date', 'svi.1', 'edgar', 'price', 'volume', 'WeeklyReturns']]\n",
    "df.rename(columns = {'svi.1':'svi'}, inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['returns'] = df['WeeklyReturns'].apply(lambda x: np.round(x, 0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "column_data = df['returns']\n",
    "\n",
    "# Sample a subset of your data\n",
    "sample_size = min(10000, len(column_data))  # Adjust sample size as desired\n",
    "column_sample = column_data.sample(n=sample_size, random_state=1)\n",
    "\n",
    "# Plotting the histogram with the sampled data\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(column_sample, kde=True)\n",
    "plt.title('Histogram of the Column (Sampled Data)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>symbol</th>\n",
       "      <th>date</th>\n",
       "      <th>svi</th>\n",
       "      <th>edgar</th>\n",
       "      <th>price</th>\n",
       "      <th>volume</th>\n",
       "      <th>WeeklyReturns</th>\n",
       "      <th>returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>NVDA</td>\n",
       "      <td>2008-10-26</td>\n",
       "      <td>21038</td>\n",
       "      <td>923</td>\n",
       "      <td>8.760</td>\n",
       "      <td>94875627.0</td>\n",
       "      <td>32.526475</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3006</th>\n",
       "      <td>AMZN</td>\n",
       "      <td>2007-04-22</td>\n",
       "      <td>22278</td>\n",
       "      <td>986</td>\n",
       "      <td>62.601</td>\n",
       "      <td>246291936.0</td>\n",
       "      <td>39.268076</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8861</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2008-11-23</td>\n",
       "      <td>123885</td>\n",
       "      <td>13652</td>\n",
       "      <td>31.660</td>\n",
       "      <td>321637800.0</td>\n",
       "      <td>39.348592</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8876</th>\n",
       "      <td>JPM</td>\n",
       "      <td>2009-03-08</td>\n",
       "      <td>181698</td>\n",
       "      <td>20797</td>\n",
       "      <td>23.750</td>\n",
       "      <td>709984200.0</td>\n",
       "      <td>49.089768</td>\n",
       "      <td>49.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9817</th>\n",
       "      <td>UNH</td>\n",
       "      <td>2008-10-12</td>\n",
       "      <td>205216</td>\n",
       "      <td>2095</td>\n",
       "      <td>24.390</td>\n",
       "      <td>81408500.0</td>\n",
       "      <td>40.576369</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374840</th>\n",
       "      <td>GIII</td>\n",
       "      <td>2011-12-04</td>\n",
       "      <td>200466</td>\n",
       "      <td>733</td>\n",
       "      <td>24.790</td>\n",
       "      <td>4477651.0</td>\n",
       "      <td>36.208791</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375275</th>\n",
       "      <td>GIII</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.350</td>\n",
       "      <td>9906317.0</td>\n",
       "      <td>82.218310</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375283</th>\n",
       "      <td>GIII</td>\n",
       "      <td>2020-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>196</td>\n",
       "      <td>16.700</td>\n",
       "      <td>10930184.0</td>\n",
       "      <td>61.665053</td>\n",
       "      <td>62.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375307</th>\n",
       "      <td>GIII</td>\n",
       "      <td>2020-11-15</td>\n",
       "      <td>0</td>\n",
       "      <td>72</td>\n",
       "      <td>21.430</td>\n",
       "      <td>6602550.0</td>\n",
       "      <td>31.391784</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375376</th>\n",
       "      <td>GIII</td>\n",
       "      <td>2022-03-13</td>\n",
       "      <td>0</td>\n",
       "      <td>614</td>\n",
       "      <td>31.420</td>\n",
       "      <td>3810247.0</td>\n",
       "      <td>30.916667</td>\n",
       "      <td>31.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>342 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       symbol        date     svi  edgar   price       volume  WeeklyReturns  \\\n",
       "2123     NVDA  2008-10-26   21038    923   8.760   94875627.0      32.526475   \n",
       "3006     AMZN  2007-04-22   22278    986  62.601  246291936.0      39.268076   \n",
       "8861      JPM  2008-11-23  123885  13652  31.660  321637800.0      39.348592   \n",
       "8876      JPM  2009-03-08  181698  20797  23.750  709984200.0      49.089768   \n",
       "9817      UNH  2008-10-12  205216   2095  24.390   81408500.0      40.576369   \n",
       "...       ...         ...     ...    ...     ...          ...            ...   \n",
       "374840   GIII  2011-12-04  200466    733  24.790    4477651.0      36.208791   \n",
       "375275   GIII  2020-04-05       0      0  10.350    9906317.0      82.218310   \n",
       "375283   GIII  2020-05-31       0    196  16.700   10930184.0      61.665053   \n",
       "375307   GIII  2020-11-15       0     72  21.430    6602550.0      31.391784   \n",
       "375376   GIII  2022-03-13       0    614  31.420    3810247.0      30.916667   \n",
       "\n",
       "        returns  \n",
       "2123       33.0  \n",
       "3006       39.0  \n",
       "8861       39.0  \n",
       "8876       49.0  \n",
       "9817       41.0  \n",
       "...         ...  \n",
       "374840     36.0  \n",
       "375275     82.0  \n",
       "375283     62.0  \n",
       "375307     31.0  \n",
       "375376     31.0  \n",
       "\n",
       "[342 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['returns']>30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1st Quartile (Q1): -2.0\n",
      "Median (Q2): -0.0\n",
      "3rd Quartile (Q3): 2.0\n"
     ]
    }
   ],
   "source": [
    "# Getting specific quartiles\n",
    "Q1 = column_data.quantile(0.25)\n",
    "Q2 = column_data.quantile(0.5)  # Median\n",
    "Q3 = column_data.quantile(0.75)\n",
    "\n",
    "print(f\"1st Quartile (Q1): {Q1}\")\n",
    "print(f\"Median (Q2): {Q2}\")\n",
    "print(f\"3rd Quartile (Q3): {Q3}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labeling returns\n",
    "def labeling(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          if r <= 2:\n",
    "               l = 1\n",
    "          else : \n",
    "               l = 2\n",
    "\n",
    "     elif r < 0:\n",
    "          if r >= -2:\n",
    "               l = 3\n",
    "          else : \n",
    "               l = 4\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling)\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagger(df, col,num):\n",
    "    df[f'shifted-({num})']  = df[col].shift(num)\n",
    "    return df\n",
    "\n",
    "def ticker_initialization(symbol, lag):\n",
    "     df_symbol = df.loc[df['symbol'] == symbol]\n",
    "     df_symbol = lagger(df_symbol, 'labeled_returns', -lag)\n",
    "     \n",
    "     start = 0\n",
    "     end = len(df_symbol) - lag\n",
    "     df_symbol = df_symbol[start:end]\n",
    "     df_symbol.reset_index(inplace = True)\n",
    "\n",
    "     return df_symbol\n",
    "\n",
    "def standardize(column):\n",
    "    mean_value = column.mean()\n",
    "    std_dev = column.std()\n",
    "    scaled_column = (column - mean_value) / std_dev\n",
    "    return scaled_column\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m x\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x' is not defined"
     ]
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(244840, 2, 2) (244840,)\n"
     ]
    }
   ],
   "source": [
    "# creating batches and test, train size\n",
    "Xs, ys = [], []\n",
    "for t in df['symbol'].unique():\n",
    "     lag = 1\n",
    "     x = ticker_initialization(t , lag)\n",
    "     x['input-1'] = standardize(x['svi'])\n",
    "     x['input-2'] = standardize(x['edgar'])\n",
    "     x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "     X = x[['input-1', 'input-2']]\n",
    "     y = x['output']\n",
    "     time_steps = 2\n",
    "     \n",
    "     for i in range(len(X) - time_steps):\n",
    "          x_array = X.iloc[i:(i + time_steps)].values\n",
    "          y_array = y.iloc[i + time_steps]\n",
    "          if not np.isnan(x_array).any():\n",
    "               if not np.isnan(y_array).any() :\n",
    "                    Xs.append(x_array)\n",
    "                    ys.append(y_array)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "print(X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 9s 22ms/step - loss: 1.5930 - accuracy: 0.2402 - val_loss: 1.5715 - val_accuracy: 0.2746\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 1.5916 - accuracy: 0.2441 - val_loss: 1.5719 - val_accuracy: 0.2731\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 5s 19ms/step - loss: 1.5908 - accuracy: 0.2456 - val_loss: 1.5711 - val_accuracy: 0.2716\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Assuming your labels are integer encoded, convert them to one-hot\n",
    "y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "# number_of_features is the number of features in your input data\n",
    "number_of_features = X.shape[1]\n",
    "\n",
    "# Adjust the model for multiclass classification\n",
    "model = Sequential([\n",
    "    LSTM(50, return_sequences=True, input_shape=(time_steps, number_of_features)),\n",
    "    Dropout(0.2),\n",
    "    LSTM(100, return_sequences=False),\n",
    "    Dropout(0.2),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "])\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Fit the model using the one-hot encoded labels\n",
    "history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                    validation_data=(X_test, y_test_onehot),\n",
    "                    verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 123, 'time_steps': 123}]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "results.append({'acc':123, 'time_steps': 123})\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 32s 116ms/step - loss: 1.5920 - accuracy: 0.2450 - val_loss: 1.5643 - val_accuracy: 0.2761\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 28s 115ms/step - loss: 1.5908 - accuracy: 0.2492 - val_loss: 1.5683 - val_accuracy: 0.2753\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 27s 112ms/step - loss: 1.5900 - accuracy: 0.2501 - val_loss: 1.5679 - val_accuracy: 0.2741\n",
      "0.2740858495235443\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 34s 127ms/step - loss: 1.5925 - accuracy: 0.2427 - val_loss: 1.5668 - val_accuracy: 0.2730\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 28s 116ms/step - loss: 1.5912 - accuracy: 0.2472 - val_loss: 1.5674 - val_accuracy: 0.2752\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 26s 109ms/step - loss: 1.5906 - accuracy: 0.2486 - val_loss: 1.5688 - val_accuracy: 0.2736\n",
      "0.2735670804977417\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 34s 128ms/step - loss: 1.5926 - accuracy: 0.2453 - val_loss: 1.5640 - val_accuracy: 0.2761\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 29s 122ms/step - loss: 1.5908 - accuracy: 0.2490 - val_loss: 1.5664 - val_accuracy: 0.2740\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 29s 121ms/step - loss: 1.5896 - accuracy: 0.2502 - val_loss: 1.5659 - val_accuracy: 0.2737\n",
      "0.2737278938293457\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 36s 134ms/step - loss: 1.5923 - accuracy: 0.2434 - val_loss: 1.5656 - val_accuracy: 0.2724\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 34s 139ms/step - loss: 1.5908 - accuracy: 0.2492 - val_loss: 1.5665 - val_accuracy: 0.2736\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 32s 132ms/step - loss: 1.5899 - accuracy: 0.2504 - val_loss: 1.5651 - val_accuracy: 0.2722\n",
      "0.27216073870658875\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 37s 140ms/step - loss: 1.5923 - accuracy: 0.2438 - val_loss: 1.5641 - val_accuracy: 0.2774\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 33s 136ms/step - loss: 1.5909 - accuracy: 0.2479 - val_loss: 1.5641 - val_accuracy: 0.2732\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5897 - accuracy: 0.2505 - val_loss: 1.5645 - val_accuracy: 0.2743\n",
      "0.2743166983127594\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 38s 146ms/step - loss: 1.5925 - accuracy: 0.2429 - val_loss: 1.5654 - val_accuracy: 0.2741\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5916 - accuracy: 0.2468 - val_loss: 1.5683 - val_accuracy: 0.2741\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 34s 140ms/step - loss: 1.5903 - accuracy: 0.2485 - val_loss: 1.5671 - val_accuracy: 0.2757\n",
      "0.27566108107566833\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 41s 155ms/step - loss: 1.5927 - accuracy: 0.2418 - val_loss: 1.5673 - val_accuracy: 0.2746\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 37s 153ms/step - loss: 1.5915 - accuracy: 0.2467 - val_loss: 1.5696 - val_accuracy: 0.2752\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 35s 146ms/step - loss: 1.5904 - accuracy: 0.2476 - val_loss: 1.5677 - val_accuracy: 0.2756\n",
      "0.2755579948425293\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 41s 156ms/step - loss: 1.5922 - accuracy: 0.2419 - val_loss: 1.5657 - val_accuracy: 0.2751\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 37s 155ms/step - loss: 1.5916 - accuracy: 0.2452 - val_loss: 1.5681 - val_accuracy: 0.2732\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 37s 154ms/step - loss: 1.5900 - accuracy: 0.2495 - val_loss: 1.5658 - val_accuracy: 0.2754\n",
      "0.27543801069259644\n",
      "Epoch 1/3\n",
      "240/240 [==============================] - 42s 162ms/step - loss: 1.5928 - accuracy: 0.2433 - val_loss: 1.5658 - val_accuracy: 0.2757\n",
      "Epoch 2/3\n",
      "240/240 [==============================] - 39s 160ms/step - loss: 1.5915 - accuracy: 0.2460 - val_loss: 1.5657 - val_accuracy: 0.2758\n",
      "Epoch 3/3\n",
      "240/240 [==============================] - 42s 176ms/step - loss: 1.5904 - accuracy: 0.2491 - val_loss: 1.5659 - val_accuracy: 0.2739\n",
      "0.27386459708213806\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,25,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'acc': 0.2714589238166809, 'time_steps': 2},\n",
       " {'acc': 0.27156174182891846, 'time_steps': 3},\n",
       " {'acc': 0.2733061611652374, 'time_steps': 4},\n",
       " {'acc': 0.27207183837890625, 'time_steps': 5},\n",
       " {'acc': 0.2734266221523285, 'time_steps': 6},\n",
       " {'acc': 0.27332282066345215, 'time_steps': 7},\n",
       " {'acc': 0.27441859245300293, 'time_steps': 8},\n",
       " {'acc': 0.27429914474487305, 'time_steps': 9},\n",
       " {'acc': 0.27386656403541565, 'time_steps': 10},\n",
       " {'acc': 0.2753453552722931, 'time_steps': 11},\n",
       " {'acc': 0.2750449776649475, 'time_steps': 12},\n",
       " {'acc': 0.27419888973236084, 'time_steps': 13},\n",
       " {'acc': 0.2769060432910919, 'time_steps': 14},\n",
       " {'acc': 0.2757952809333801, 'time_steps': 15},\n",
       " {'acc': 0.2740858495235443, 'time_steps': 16},\n",
       " {'acc': 0.2735670804977417, 'time_steps': 17},\n",
       " {'acc': 0.2737278938293457, 'time_steps': 18},\n",
       " {'acc': 0.27216073870658875, 'time_steps': 19},\n",
       " {'acc': 0.2743166983127594, 'time_steps': 20},\n",
       " {'acc': 0.27566108107566833, 'time_steps': 21},\n",
       " {'acc': 0.2755579948425293, 'time_steps': 22},\n",
       " {'acc': 0.27543801069259644, 'time_steps': 23},\n",
       " {'acc': 0.27386459708213806, 'time_steps': 24}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "245/245 [==============================] - 10s 25ms/step - loss: 1.0762 - accuracy: 0.4504 - val_loss: 0.9713 - val_accuracy: 0.4283\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 5s 22ms/step - loss: 0.9954 - accuracy: 0.4627 - val_loss: 0.9704 - val_accuracy: 0.4283\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 5s 21ms/step - loss: 0.9947 - accuracy: 0.4636 - val_loss: 0.9703 - val_accuracy: 0.4283\n",
      "0.42834505438804626\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 11s 30ms/step - loss: 1.0680 - accuracy: 0.4577 - val_loss: 0.9699 - val_accuracy: 0.4284\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 7s 29ms/step - loss: 0.9959 - accuracy: 0.4620 - val_loss: 0.9695 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 7s 27ms/step - loss: 0.9950 - accuracy: 0.4632 - val_loss: 0.9691 - val_accuracy: 0.4284\n",
      "0.428372859954834\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 14s 40ms/step - loss: 1.0609 - accuracy: 0.4527 - val_loss: 0.9698 - val_accuracy: 0.4291\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 9s 36ms/step - loss: 0.9957 - accuracy: 0.4605 - val_loss: 0.9702 - val_accuracy: 0.4288\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 9s 37ms/step - loss: 0.9948 - accuracy: 0.4627 - val_loss: 0.9702 - val_accuracy: 0.4287\n",
      "0.42866963148117065\n",
      "Epoch 1/3\n",
      "245/245 [==============================] - 15s 46ms/step - loss: 1.0597 - accuracy: 0.4567 - val_loss: 0.9705 - val_accuracy: 0.4287\n",
      "Epoch 2/3\n",
      "245/245 [==============================] - 11s 45ms/step - loss: 0.9959 - accuracy: 0.4604 - val_loss: 0.9693 - val_accuracy: 0.4286\n",
      "Epoch 3/3\n",
      "245/245 [==============================] - 11s 44ms/step - loss: 0.9948 - accuracy: 0.4630 - val_loss: 0.9687 - val_accuracy: 0.4287\n",
      "0.4286557137966156\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 17s 53ms/step - loss: 1.0505 - accuracy: 0.4533 - val_loss: 0.9699 - val_accuracy: 0.4360\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 12s 47ms/step - loss: 0.9963 - accuracy: 0.4615 - val_loss: 0.9696 - val_accuracy: 0.4285\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 12s 49ms/step - loss: 0.9952 - accuracy: 0.4624 - val_loss: 0.9694 - val_accuracy: 0.4285\n",
      "0.4285432994365692\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 18s 58ms/step - loss: 1.0481 - accuracy: 0.4533 - val_loss: 0.9721 - val_accuracy: 0.4287\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 14s 58ms/step - loss: 0.9965 - accuracy: 0.4613 - val_loss: 0.9706 - val_accuracy: 0.4287\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 14s 57ms/step - loss: 0.9952 - accuracy: 0.4624 - val_loss: 0.9694 - val_accuracy: 0.4287\n",
      "0.4286605715751648\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 21s 69ms/step - loss: 1.0436 - accuracy: 0.4488 - val_loss: 0.9683 - val_accuracy: 0.4417\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 16s 66ms/step - loss: 0.9971 - accuracy: 0.4567 - val_loss: 0.9686 - val_accuracy: 0.4328\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 15s 63ms/step - loss: 0.9954 - accuracy: 0.4599 - val_loss: 0.9686 - val_accuracy: 0.4283\n",
      "0.4283014237880707\n",
      "Epoch 1/3\n",
      "244/244 [==============================] - 21s 72ms/step - loss: 1.0418 - accuracy: 0.4517 - val_loss: 0.9693 - val_accuracy: 0.4284\n",
      "Epoch 2/3\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.9948 - accuracy: 0.4592 - val_loss: 0.9717 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "244/244 [==============================] - 17s 68ms/step - loss: 0.9944 - accuracy: 0.4619 - val_loss: 0.9709 - val_accuracy: 0.4284\n",
      "0.4284351170063019\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 23s 79ms/step - loss: 1.0433 - accuracy: 0.4471 - val_loss: 0.9695 - val_accuracy: 0.4308\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 18s 76ms/step - loss: 0.9962 - accuracy: 0.4592 - val_loss: 0.9696 - val_accuracy: 0.4284\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 18s 75ms/step - loss: 0.9952 - accuracy: 0.4612 - val_loss: 0.9692 - val_accuracy: 0.4284\n",
      "0.42840439081192017\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 25s 86ms/step - loss: 1.0345 - accuracy: 0.4488 - val_loss: 0.9709 - val_accuracy: 0.4390\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 20s 81ms/step - loss: 0.9963 - accuracy: 0.4582 - val_loss: 0.9690 - val_accuracy: 0.4283\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 20s 82ms/step - loss: 0.9952 - accuracy: 0.4605 - val_loss: 0.9683 - val_accuracy: 0.4279\n",
      "0.42787906527519226\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 27s 94ms/step - loss: 1.0352 - accuracy: 0.4521 - val_loss: 0.9711 - val_accuracy: 0.4289\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 22s 91ms/step - loss: 0.9964 - accuracy: 0.4580 - val_loss: 0.9703 - val_accuracy: 0.4295\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 22s 89ms/step - loss: 0.9948 - accuracy: 0.4608 - val_loss: 0.9684 - val_accuracy: 0.4289\n",
      "0.4288873076438904\n",
      "Epoch 1/3\n",
      "243/243 [==============================] - 28s 101ms/step - loss: 1.0404 - accuracy: 0.4532 - val_loss: 0.9717 - val_accuracy: 0.4281\n",
      "Epoch 2/3\n",
      "243/243 [==============================] - 24s 98ms/step - loss: 0.9960 - accuracy: 0.4619 - val_loss: 0.9701 - val_accuracy: 0.4281\n",
      "Epoch 3/3\n",
      "243/243 [==============================] - 23s 96ms/step - loss: 0.9947 - accuracy: 0.4629 - val_loss: 0.9696 - val_accuracy: 0.4281\n",
      "0.4280640780925751\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 29s 106ms/step - loss: 1.0451 - accuracy: 0.4460 - val_loss: 0.9688 - val_accuracy: 0.4384\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 24s 101ms/step - loss: 0.9962 - accuracy: 0.4597 - val_loss: 0.9697 - val_accuracy: 0.4338\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 25s 103ms/step - loss: 0.9946 - accuracy: 0.4623 - val_loss: 0.9701 - val_accuracy: 0.4276\n",
      "0.4276195168495178\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 31s 114ms/step - loss: 1.0340 - accuracy: 0.4528 - val_loss: 0.9697 - val_accuracy: 0.4324\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 26s 108ms/step - loss: 0.9955 - accuracy: 0.4608 - val_loss: 0.9713 - val_accuracy: 0.4287\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 27s 110ms/step - loss: 0.9947 - accuracy: 0.4615 - val_loss: 0.9698 - val_accuracy: 0.4301\n",
      "0.43013671040534973\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_2(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          l = 1\n",
    "     elif r < 0:\n",
    "          l = 2\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_2)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(2,16,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=5)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=5)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(5, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.9982 - accuracy: 0.4640 - val_loss: 0.9669 - val_accuracy: 0.4457\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.9934 - accuracy: 0.4645 - val_loss: 0.9658 - val_accuracy: 0.4542\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.9927 - accuracy: 0.4650 - val_loss: 0.9654 - val_accuracy: 0.4596\n",
      "0.45956557989120483\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_2(r):\n",
    "     if r == 0:\n",
    "          l = 0\n",
    "     elif r > 0:\n",
    "          l = 1\n",
    "     elif r < 0:\n",
    "          l = 2\n",
    "     else:\n",
    "          l = None\n",
    "     return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_2)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,17,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=3)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=3)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(3, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':123})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('results-checkpoint', results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([{'acc': 0.2714589238166809, 'time_steps': 2},\n",
       "       {'acc': 0.27156174182891846, 'time_steps': 3},\n",
       "       {'acc': 0.2733061611652374, 'time_steps': 4},\n",
       "       {'acc': 0.27207183837890625, 'time_steps': 5},\n",
       "       {'acc': 0.2734266221523285, 'time_steps': 6},\n",
       "       {'acc': 0.27332282066345215, 'time_steps': 7},\n",
       "       {'acc': 0.27441859245300293, 'time_steps': 8},\n",
       "       {'acc': 0.27429914474487305, 'time_steps': 9},\n",
       "       {'acc': 0.27386656403541565, 'time_steps': 10},\n",
       "       {'acc': 0.2753453552722931, 'time_steps': 11},\n",
       "       {'acc': 0.2750449776649475, 'time_steps': 12},\n",
       "       {'acc': 0.27419888973236084, 'time_steps': 13},\n",
       "       {'acc': 0.2769060432910919, 'time_steps': 14},\n",
       "       {'acc': 0.2757952809333801, 'time_steps': 15},\n",
       "       {'acc': 0.2740858495235443, 'time_steps': 16},\n",
       "       {'acc': 0.2735670804977417, 'time_steps': 17},\n",
       "       {'acc': 0.2737278938293457, 'time_steps': 18},\n",
       "       {'acc': 0.27216073870658875, 'time_steps': 19},\n",
       "       {'acc': 0.2743166983127594, 'time_steps': 20},\n",
       "       {'acc': 0.27566108107566833, 'time_steps': 21},\n",
       "       {'acc': 0.2755579948425293, 'time_steps': 22},\n",
       "       {'acc': 0.27543801069259644, 'time_steps': 23},\n",
       "       {'acc': 0.27386459708213806, 'time_steps': 24},\n",
       "       {'acc': 0.42834505438804626, 'time_steps': 2, 'new': 123},\n",
       "       {'acc': 0.428372859954834, 'time_steps': 3, 'new': 123},\n",
       "       {'acc': 0.42866963148117065, 'time_steps': 4, 'new': 123},\n",
       "       {'acc': 0.4286557137966156, 'time_steps': 5, 'new': 123},\n",
       "       {'acc': 0.4285432994365692, 'time_steps': 6, 'new': 123},\n",
       "       {'acc': 0.4286605715751648, 'time_steps': 7, 'new': 123},\n",
       "       {'acc': 0.4283014237880707, 'time_steps': 8, 'new': 123},\n",
       "       {'acc': 0.4284351170063019, 'time_steps': 9, 'new': 123},\n",
       "       {'acc': 0.42840439081192017, 'time_steps': 10, 'new': 123},\n",
       "       {'acc': 0.42787906527519226, 'time_steps': 11, 'new': 123},\n",
       "       {'acc': 0.4288873076438904, 'time_steps': 12, 'new': 123},\n",
       "       {'acc': 0.4280640780925751, 'time_steps': 13, 'new': 123},\n",
       "       {'acc': 0.4276195168495178, 'time_steps': 14, 'new': 123},\n",
       "       {'acc': 0.43013671040534973, 'time_steps': 15, 'new': 123},\n",
       "       {'acc': 0.4284175932407379, 'time_steps': 16, 'new': 123},\n",
       "       {'acc': 0.42777299880981445, 'time_steps': 17, 'new': 123},\n",
       "       {'acc': 0.4275919198989868, 'time_steps': 18, 'new': 123},\n",
       "       {'acc': 0.427875816822052, 'time_steps': 19, 'new': 123},\n",
       "       {'acc': 0.42791077494621277, 'time_steps': 20, 'new': 123},\n",
       "       {'acc': 0.44436487555503845, 'time_steps': 21, 'new': 123},\n",
       "       {'acc': 0.4283309280872345, 'time_steps': 22, 'new': 123},\n",
       "       {'acc': 0.4288002550601959, 'time_steps': 23, 'new': 123},\n",
       "       {'acc': 0.42796772718429565, 'time_steps': 24, 'new': 123},\n",
       "       {'acc': 0.4281199872493744, 'time_steps': 25, 'new': 123}],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = np.load('results-checkpoint.npy', allow_pickle=True)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 24s 83ms/step - loss: 0.6832 - accuracy: 0.5618 - val_loss: 0.6930 - val_accuracy: 0.4975\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.6827 - accuracy: 0.5602 - val_loss: 0.6938 - val_accuracy: 0.4747\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 78ms/step - loss: 0.6821 - accuracy: 0.5627 - val_loss: 0.6940 - val_accuracy: 0.4718\n",
      "0.4717928469181061\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 28s 99ms/step - loss: 0.6836 - accuracy: 0.5608 - val_loss: 0.6940 - val_accuracy: 0.4710\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 23s 96ms/step - loss: 0.6832 - accuracy: 0.5597 - val_loss: 0.6943 - val_accuracy: 0.4768\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 23s 95ms/step - loss: 0.6826 - accuracy: 0.5627 - val_loss: 0.6945 - val_accuracy: 0.4724\n",
      "0.47235307097435\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 28s 99ms/step - loss: 0.6834 - accuracy: 0.5618 - val_loss: 0.6937 - val_accuracy: 0.4831\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 22s 90ms/step - loss: 0.6828 - accuracy: 0.5606 - val_loss: 0.6943 - val_accuracy: 0.4710\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 22s 90ms/step - loss: 0.6820 - accuracy: 0.5630 - val_loss: 0.6947 - val_accuracy: 0.4712\n",
      "0.47122105956077576\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_3(r):\n",
    "    if -2 <= r <= 2:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -2 or r > 2:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_3)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 25s 85ms/step - loss: 0.5213 - accuracy: 0.7876 - val_loss: 0.6120 - val_accuracy: 0.6935\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 0.5145 - accuracy: 0.7883 - val_loss: 0.6123 - val_accuracy: 0.6935\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 79ms/step - loss: 0.5129 - accuracy: 0.7883 - val_loss: 0.6127 - val_accuracy: 0.6935\n",
      "0.693540096282959\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 26s 92ms/step - loss: 0.5234 - accuracy: 0.7861 - val_loss: 0.6118 - val_accuracy: 0.6935\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 21s 86ms/step - loss: 0.5149 - accuracy: 0.7883 - val_loss: 0.6119 - val_accuracy: 0.6935\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 21s 86ms/step - loss: 0.5134 - accuracy: 0.7883 - val_loss: 0.6120 - val_accuracy: 0.6935\n",
      "0.6935120224952698\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 26s 93ms/step - loss: 0.5222 - accuracy: 0.7870 - val_loss: 0.6121 - val_accuracy: 0.6936\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 21s 87ms/step - loss: 0.5145 - accuracy: 0.7883 - val_loss: 0.6124 - val_accuracy: 0.6936\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 21s 86ms/step - loss: 0.5128 - accuracy: 0.7883 - val_loss: 0.6129 - val_accuracy: 0.6936\n",
      "0.6935834884643555\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r):\n",
    "    if -4 <= r <= 4:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -4 or r > 4:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_4)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'very extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "242/242 [==============================] - 25s 85ms/step - loss: 0.3568 - accuracy: 0.8894 - val_loss: 0.4691 - val_accuracy: 0.8178\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 19s 80ms/step - loss: 0.3402 - accuracy: 0.8930 - val_loss: 0.4687 - val_accuracy: 0.8178\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 19s 80ms/step - loss: 0.3385 - accuracy: 0.8930 - val_loss: 0.4688 - val_accuracy: 0.8178\n",
      "0.8177510499954224\n",
      "Epoch 1/3\n",
      "242/242 [==============================] - 27s 92ms/step - loss: 0.3567 - accuracy: 0.8910 - val_loss: 0.4693 - val_accuracy: 0.8177\n",
      "Epoch 2/3\n",
      "242/242 [==============================] - 22s 89ms/step - loss: 0.3409 - accuracy: 0.8930 - val_loss: 0.4691 - val_accuracy: 0.8177\n",
      "Epoch 3/3\n",
      "242/242 [==============================] - 22s 89ms/step - loss: 0.3386 - accuracy: 0.8930 - val_loss: 0.4690 - val_accuracy: 0.8177\n",
      "0.8176827430725098\n",
      "Epoch 1/3\n",
      "241/241 [==============================] - 28s 100ms/step - loss: 0.3607 - accuracy: 0.8874 - val_loss: 0.4687 - val_accuracy: 0.8177\n",
      "Epoch 2/3\n",
      "241/241 [==============================] - 22s 93ms/step - loss: 0.3396 - accuracy: 0.8930 - val_loss: 0.4690 - val_accuracy: 0.8177\n",
      "Epoch 3/3\n",
      "241/241 [==============================] - 23s 93ms/step - loss: 0.3387 - accuracy: 0.8930 - val_loss: 0.4691 - val_accuracy: 0.8177\n",
      "0.8176973462104797\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r):\n",
    "    if -6 <= r <= 6:  # Simplified range check\n",
    "        l = 0\n",
    "    elif r < -6 or r > 6:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "df['labeled_returns'] = df['returns'].apply(labeling_4)\n",
    "\n",
    "\n",
    "# results = []\n",
    "for tl in np.arange(16,19,1):\n",
    "     Xs, ys = [], []\n",
    "     for t in df['symbol'].unique():\n",
    "          lag = 1\n",
    "          x = ticker_initialization(t , lag)\n",
    "          x['input-1'] = standardize(x['svi'])\n",
    "          x['input-2'] = standardize(x['edgar'])\n",
    "          x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "          X = x[['input-1', 'input-2']]\n",
    "          y = x['output']\n",
    "          time_steps = tl\n",
    "          \n",
    "          for i in range(len(X) - time_steps):\n",
    "               x_array = X.iloc[i:(i + time_steps)].values\n",
    "               y_array = y.iloc[i + time_steps]\n",
    "               if not np.isnan(x_array).any():\n",
    "                    if not np.isnan(y_array).any() :\n",
    "                         Xs.append(x_array)\n",
    "                         ys.append(y_array)\n",
    "\n",
    "     X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "     y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "     y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "     # number_of_features is the number of features in your input data\n",
    "     number_of_features = X.shape[1]\n",
    "\n",
    "     # Adjust the model for multiclass classification\n",
    "     model = Sequential([\n",
    "     LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "     Dropout(0.2),\n",
    "     LSTM(100, return_sequences=False),\n",
    "     Dropout(0.2),\n",
    "     Dense(50, activation='relu'),\n",
    "     Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "     ])\n",
    "     model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "     early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "     # Fit the model using the one-hot encoded labels\n",
    "     history = model.fit(X_train, y_train_onehot, epochs=3, batch_size=1000,\n",
    "                         validation_data=(X_test, y_test_onehot),\n",
    "                         verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "     acc = history.history['val_accuracy'][-1]\n",
    "     print(acc)\n",
    "     results.append({'acc':acc, 'time_steps': tl, 'new':'very very extreme'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "311.4485902178977"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['returns'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "242/242 [==============================] - 24s 83ms/step - loss: 0.1771 - accuracy: 0.9607 - val_loss: 0.2576 - val_accuracy: 0.9278\n",
      "0.9277963042259216\n",
      "242/242 [==============================] - 25s 86ms/step - loss: 0.0933 - accuracy: 0.9847 - val_loss: 0.1322 - val_accuracy: 0.9701\n",
      "0.9701443314552307\n",
      "242/242 [==============================] - 24s 83ms/step - loss: 0.0774 - accuracy: 0.9840 - val_loss: 0.0784 - val_accuracy: 0.9849\n",
      "0.9848899245262146\n",
      "242/242 [==============================] - 24s 80ms/step - loss: 0.0481 - accuracy: 0.9961 - val_loss: 0.0532 - val_accuracy: 0.9904\n",
      "0.9904070496559143\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.0690 - accuracy: 0.9924 - val_loss: 0.0771 - val_accuracy: 0.9849\n",
      "0.9848899245262146\n",
      "242/242 [==============================] - 23s 78ms/step - loss: 0.0561 - accuracy: 0.9932 - val_loss: 0.0532 - val_accuracy: 0.9904\n",
      "0.9904070496559143\n",
      "242/242 [==============================] - 24s 81ms/step - loss: 0.0433 - accuracy: 0.9957 - val_loss: 0.0410 - val_accuracy: 0.9932\n",
      "0.993240237236023\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0410 - accuracy: 0.9937 - val_loss: 0.0325 - val_accuracy: 0.9948\n",
      "0.9948307275772095\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0350 - accuracy: 0.9982 - val_loss: 0.0291 - val_accuracy: 0.9956\n",
      "0.9955928921699524\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0460 - accuracy: 0.9910 - val_loss: 0.0257 - val_accuracy: 0.9962\n",
      "0.9961727857589722\n",
      "242/242 [==============================] - 24s 79ms/step - loss: 0.0348 - accuracy: 0.9970 - val_loss: 0.0240 - val_accuracy: 0.9966\n",
      "0.9965869784355164\n",
      "242/242 [==============================] - 23s 79ms/step - loss: 0.0371 - accuracy: 0.9953 - val_loss: 0.0227 - val_accuracy: 0.9968\n",
      "0.9968023300170898\n",
      "242/242 [==============================] - 23s 77ms/step - loss: 0.0320 - accuracy: 0.9969 - val_loss: 0.0219 - val_accuracy: 0.9970\n",
      "0.9969680309295654\n"
     ]
    }
   ],
   "source": [
    "# labeling returns\n",
    "def labeling_4(r,e):\n",
    "    if -e <= r <= e: \n",
    "        l = 0\n",
    "    elif r < -e or r > e:\n",
    "        l = 1\n",
    "    else:\n",
    "        l = None\n",
    "    return l\n",
    "\n",
    "\n",
    "for e in [10,15,20,25,20,25,30,35,40,45,50,55,60]:\n",
    "\n",
    "     df['labeled_returns'] = df['returns'].apply(lambda x: labeling_4(x,e))\n",
    "     # results = []\n",
    "     for tl in np.arange(16,17,1):\n",
    "          Xs, ys = [], []\n",
    "          for t in df['symbol'].unique():\n",
    "               lag = 1\n",
    "               x = ticker_initialization(t , lag)\n",
    "               x['input-1'] = standardize(x['svi'])\n",
    "               x['input-2'] = standardize(x['edgar'])\n",
    "               x['output'] = x[f'shifted-(-{lag})']\n",
    "\n",
    "               X = x[['input-1', 'input-2']]\n",
    "               y = x['output']\n",
    "               time_steps = tl\n",
    "               \n",
    "               for i in range(len(X) - time_steps):\n",
    "                    x_array = X.iloc[i:(i + time_steps)].values\n",
    "                    y_array = y.iloc[i + time_steps]\n",
    "                    if not np.isnan(x_array).any():\n",
    "                         if not np.isnan(y_array).any() :\n",
    "                              Xs.append(x_array)\n",
    "                              ys.append(y_array)\n",
    "\n",
    "          X_train, X_test, y_train, y_test = train_test_split(np.array(Xs), np.array(ys), test_size=0.20, shuffle=False)\n",
    "\n",
    "          y_train_onehot = to_categorical(y_train, num_classes=2)\n",
    "          y_test_onehot = to_categorical(y_test, num_classes=2)\n",
    "\n",
    "          # number_of_features is the number of features in your input data\n",
    "          number_of_features = X.shape[1]\n",
    "\n",
    "          # Adjust the model for multiclass classification\n",
    "          model = Sequential([\n",
    "          LSTM(50, return_sequences=True, input_shape=(tl, number_of_features)),\n",
    "          Dropout(0.2),\n",
    "          LSTM(100, return_sequences=False),\n",
    "          Dropout(0.2),\n",
    "          Dense(50, activation='relu'),\n",
    "          Dense(2, activation='softmax')  # Change for multiclass classification\n",
    "          ])\n",
    "          model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "          early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "          # Fit the model using the one-hot encoded labels\n",
    "          history = model.fit(X_train, y_train_onehot, epochs=1, batch_size=1000,\n",
    "                              validation_data=(X_test, y_test_onehot),\n",
    "                              verbose=1, shuffle=False, callbacks=[early_stopping])\n",
    "          acc = history.history['val_accuracy'][-1]\n",
    "          print(acc)\n",
    "          results.append({'acc':acc, 'time_steps': tl, 'new':f'very very extreme {e}'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
